<p align=center><img src=https://d31uz8lwfmyn8g.cloudfront.net/Assets/logo-henry-white-lg.png><p>

# <h1 align=center> **PROYECTO INDIVIDUAL N¬∫1** </h1>
# <h1 align=center> **Tomas Fernandez - TFTomasFernandez** </h1>
# <h1 align=center>**`Machine Learning Operations (MLOps)`**</h1>


¬°Bienvenidos a mi primer proyecto individual! 

<hr>  

## Mi Rol como desarrollador

Trabajamos como **`Data Scientist`** en una start-up que provee servicios de agregaci√≥n de plataformas de streaming. Necesito crear mi primer modelo de ML que soluciona un problema de negocio: un sistema de recomendaci√≥n que a√∫n no ha sido puesto en marcha! 

Tuve que empezar desde 0, haciendo un trabajo r√°pido de **`Data Engineer`** y tener un **`MVP`** (_Minimum Viable Product_) para las pr√≥ximas semanas!,

<p align="center">
<img src="https://github.com/HX-PRomero/PI_ML_OPS/raw/main/src/DiagramaConceptualDelFlujoDeProcesos.png"  height=500>
</p>

<sub> Nota: Aqui se reflejan procesos no herramientas tecnologicas.<sub/>

## **Estas son las propuesta de trabajo que tuve que resolver**

**`Transformaciones`**:  Para este MVP no necesitas perfecci√≥n, ¬°necesitas rapidez! ‚è© Vas a hacer estas, ***y solo estas***, transformaciones a los datos:


+ Algunos campos, como **`belongs_to_collection`**, **`production_companies`** y otros (ver diccionario de datos) est√°n anidados, esto es o bien tienen un diccionario o una lista como valores en cada fila, ¬°deber√°n desanidarlos para poder  y unirlos al dataset de nuevo hacer alguna de las consultas de la API! O bien buscar la manera de acceder a esos datos sin desanidarlos.

+ Los valores nulos de los campos **`revenue`**, **`budget`** deben ser rellenados por el n√∫mero **`0`**.
  
+ Los valores nulos del campo **`release date`** deben eliminarse.

+ De haber fechas, deber√°n tener el formato **`AAAA-mm-dd`**, adem√°s deber√°n crear la columna **`release_year`** donde extraer√°n el a√±o de la fecha de estreno.

+ Crear la columna con el retorno de inversi√≥n, llamada **`return`** con los campos **`revenue`** y **`budget`**, dividiendo estas dos √∫ltimas **`revenue / budget`**, cuando no hay datos disponibles para calcularlo, deber√° tomar el valor **`0`**.

+ Eliminar las columnas que no ser√°n utilizadas, **`video`**,**`imdb_id`**,**`adult`**,**`original_title`**,**`poster_path`** y **`homepage`**.

<br/>

**`Desarrollo API`**:   Propones disponibilizar los datos de la empresa usando el framework ***FastAPI***. Las consultas que propones son las siguientes:

Deben crear 6 funciones para los endpoints que se consumir√°n en la API, recuerden que deben tener un decorador por cada una (@app.get(‚Äò/‚Äô)).
  
+ def **cantidad_filmaciones_mes( *`Mes`* )**:
    Se ingresa un mes en idioma Espa√±ol. Debe devolver la cantidad de pel√≠culas que fueron estrenadas en el mes consultado en la totalidad del dataset.

         
+ def **cantidad_filmaciones_dia( *`Dia`* )**:
    Se ingresa un d√≠a en idioma Espa√±ol. Debe devolver la cantidad de pel√≠culas que fueron estrenadas en d√≠a consultado en la totalidad del dataset.


+ def **score_titulo( *`titulo_de_la_filmaci√≥n`* )**:
    Se ingresa el t√≠tulo de una filmaci√≥n esperando como respuesta el t√≠tulo, el a√±o de estreno y el score.
    

+ def **votos_titulo( *`titulo_de_la_filmaci√≥n`* )**:
    Se ingresa el t√≠tulo de una filmaci√≥n esperando como respuesta el t√≠tulo, la cantidad de votos y el valor promedio de las votaciones. La misma variable deber√° de contar con al menos 2000 valoraciones, caso contrario, debemos contar con un mensaje avisando que no cumple esta condici√≥n y que por ende, no se devuelve ningun valor.
    

+ def **get_actor( *`nombre_actor`* )**:
    Se ingresa el nombre de un actor que se encuentre dentro de un dataset debiendo devolver el √©xito del mismo medido a trav√©s del retorno. Adem√°s, la cantidad de pel√≠culas que en las que ha participado y el promedio de retorno. **La definici√≥n no deber√° considerar directores.**
    

+ def **get_director( *`nombre_director`* )**:
    Se ingresa el nombre de un director que se encuentre dentro de un dataset debiendo devolver el √©xito del mismo medido a trav√©s del retorno. Adem√°s, deber√° devolver el nombre de cada pel√≠cula con la fecha de lanzamiento, retorno individual, costo y ganancia de la misma.



<br/>


**`Deployment`**: Utilizar [Render](https://render.com/docs/free#free-web-services), o cualquier otro servicio que permita que la API pueda ser consumida desde la web.

<br/>

**`An√°lisis exploratorio de los datos`**: _(Exploratory Data Analysis-EDA)_

Ya los datos est√°n limpios, ahora es tiempo de investigar las relaciones que hay entre las variables de los datasets, ver si hay outliers o anomal√≠as (que no tienen que ser errores necesariamente :eyes: ), y ver si hay alg√∫n patr√≥n interesante que valga la pena explorar en un an√°lisis posterior. Las nubes de palabras dan una buena idea de cu√°les palabras son m√°s frecuentes en los t√≠tulos, ¬°podr√≠a ayudar al sistema de recomendaci√≥n! Sabes que puedes apoyarte en librer√≠as como _pandas profiling, missingno, sweetviz, autoviz_, entre otros y sacar de all√≠ tus conclusiones üòâ

**`Sistema de recomendaci√≥n`**: 

Una vez que toda la data es consumible por la API, est√° lista para consumir por los departamentos de Analytics y Machine Learning, y nuestro EDA nos permite entender bien los datos a los que tenemos acceso, es hora de entrenar nuestro modelo de machine learning para armar un sistema de recomendaci√≥n de pel√≠culas. El EDA deber√≠a incluir gr√°ficas interesantes para extraer datos, como por ejemplo una nube de palabras con las palabras m√°s frecuentes en los t√≠tulos de las pel√≠culas. √âste consiste en recomendar pel√≠culas a los usuarios bas√°ndose en pel√≠culas similares, por lo que se debe encontrar la similitud de puntuaci√≥n entre esa pel√≠cula y el resto de pel√≠culas, se ordenar√°n seg√∫n el score de similaridad y devolver√° una lista de Python con 5 valores, cada uno siendo el string del nombre de las pel√≠culas con mayor puntaje, en orden descendente. Debe ser deployado como una funci√≥n adicional de la API anterior y debe llamarse:


+ def **recomendacion( *`titulo`* )**:
    Se ingresa el nombre de una pel√≠cula y te recomienda las similares en una lista de 5 valores.

<br/>

## 1. Transformaci√≥n de Datos

1. Se inici√≥ con los archivos `movies_dataset.csv` y `credits.csv` que conten√≠an informaci√≥n sobre pel√≠culas y cr√©ditos asociados.
2. Se realiz√≥ una exploraci√≥n inicial de los datos para comprender su estructura y contenido.
3. Se identificaron los problemas de calidad de los datos, como valores faltantes, duplicados o inconsistencias.
4. Se procedi√≥ a realizar la normalizaci√≥n de los datos para facilitar su procesamiento y an√°lisis a trav√©s de archivo main.ipynb:
    ### En el caso del archivo `movies_data.csv`, se realizaron las transformaciones y se export√≥ a peliculas.csv:
- [Archivo peliculas](https://github.com/TFTomasFernandez/Proyecto_1/tree/Repositorio/Datasets%20utilizados)
    ### En el caso del archivo `credits.csv`, se realizaron las transformaciones con la clase DataGuru2 y se export√≥ a df_credits_norm.csv:
- [Archivos creditos cast y crew](https://github.com/TFTomasFernandez/Proyecto_1/tree/Repositorio/Datasets%20utilizados)

## 2. An√°lisis exploratorio de los datos y sistema de recomendaci√≥n

El an√°lisis exploratorio de datos realizado consisti√≥ en el procesamiento y exploraci√≥n de los conjuntos de datos "movies_data.csv" y "credits.csv" para obtener informaci√≥n relevante sobre las pel√≠culas.

### Respecto a la consulta para recomendar peliculas, se desarollo de la siguiente manera:

1. El t√≠tulo de la pel√≠cula de entrada se convirti√≥ a min√∫sculas para evitar problemas de coincidencia de may√∫sculas y min√∫sculas.

2. Se cre√≥ una nueva columna en el DataFrame df_movies_norm que contiene los t√≠tulos en min√∫sculas.

3. El DataFrame se filtr√≥ para obtener la pel√≠cula de entrada espec√≠fica.

4. Se verific√≥ si se encontr√≥ la pel√≠cula de entrada en el conjunto de datos.

5. Se procedi√≥ a obtener los g√©neros de la pel√≠cula de entrada.

6. El DataFrame se filtr√≥ nuevamente para encontrar pel√≠culas que tuvieran al menos uno de los g√©neros de la pel√≠cula de entrada. La pel√≠cula de entrada se excluy√≥ del conjunto filtrado.

7. Las pel√≠culas resultantes se ordenaron en base a su puntuaci√≥n y popularidad, de forma descendente.

8. Se seleccionaron las 5 primeras pel√≠culas como recomendaciones.

9. Se cre√≥ una lista de diccionarios que almacenaban la informaci√≥n relevante de cada pel√≠cula recomendada, como el t√≠tulo, la fecha de lanzamiento, la puntuaci√≥n y la popularidad.

10. Se devolvi√≥ un diccionario que conten√≠a el t√≠tulo de la pel√≠cula de entrada y la lista de pel√≠culas recomendadas.

11. En caso de no encontrarse ninguna pel√≠cula con el t√≠tulo de entrada, se devolvi√≥ un mensaje indicando que no se encontr√≥ ninguna coincidencia en el conjunto de datos.

En resumen, este m√©todo proporciona una funcionalidad para recomendar pel√≠culas similares bas√°ndose en los g√©neros de una pel√≠cula de entrada espec√≠fica.

## 3. Desarrollo de la API con FastAPI
1. Se utiliz√≥ el framework FastAPI para desarrollar una API que permitiera acceder a los datos normalizados.
2. Se crearon las rutas y controladores correspondientes para manejar las solicitudes de los usuarios.
3. Se implementaron las operaciones b√°sicas de consulta y b√∫squeda de pel√≠culas, as√≠ como tambi√©n la obtenci√≥n de informaci√≥n detallada de una pel√≠cula espec√≠fica.
4. Se realizaron pruebas locales para asegurarse de que la API funcionara correctamente.

## 4. Despliegue del Proyecto en Render

1. Se configur√≥ el entorno de despliegue utilizando Render, un servicio de alojamiento y despliegue de aplicaciones web
2. Se cre√≥ un archivo de configuraci√≥n `requirements.txt` con las dependencias necesarias para el proyecto.
4. Se realiz√≥ el despliegue del proyecto en Render, asegurando que la API estuviera disponible en l√≠nea.



**`Video`**: Necesitas que al equipo le quede claro que tus herramientas funcionan realmente! Haces un video mostrando el resultado de las consultas propuestas y de tu modelo de ML entrenado!

<sub> **Spoiler**: El video NO DEBE durar mas de ***7 minutos*** y DEBE mostrar las consultas requeridas en funcionamiento desde la API y una breve explicacion del modelo utilizado para el sistema de recomendacion. En caso de que te sobre tiempo luego de grabarlo, puedes mostrar explicar tu EDA, ETL e incluso c√≥mo desarrollaste la API. <sub/>

<br/>

## **Fuente de datos**

- + [Dataset](https://drive.google.com/drive/folders/1X_LdCoGTHJDbD28_dJTxaD4fVuQC9Wt5?usp=drive_link): Carpeta con los 2 archivos con datos que requieren ser procesados (movies_dataset.csv y credits.csv), tengan en cuenta que hay datos que estan anidados (un diccionario o una lista como valores en la fila).
+ [Diccionario de datos](https://docs.google.com/spreadsheets/d/1QkHH5er-74Bpk122tJxy_0D49pJMIwKLurByOfmxzho/edit#gid=0): Diccionario con algunas descripciones de las columnas disponibles en el dataset.
<br/>
